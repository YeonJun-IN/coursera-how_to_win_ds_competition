{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from random import sample\n",
    "seed_list = list(range(10000))\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "os.chdir('C:\\\\Users\\\\yeonjun.in\\\\Desktop\\\\연준\\\\캐글\\\\제주도\\\\data')\n",
    "\n",
    "TODAY = str(datetime.now().year)+str(datetime.now().month)+str(datetime.now().day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\yeonjun.in\\\\Desktop\\\\연준\\\\캐글\\\\제주도\\\\data')\n",
    "\n",
    "train = pd.read_pickle('fixed1_train.pkl')\n",
    "test = pd.read_pickle(\"fixed1_test.pkl\")\n",
    "\n",
    "sub = pd.read_csv('submission_sample.csv')\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\yeonjun.in\\\\Desktop\\\\연준\\\\캐글\\\\제주도\\\\code\\\\experiment')\n",
    "experiment_db = pd.read_csv('experiment_DB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "added = []\n",
    "input_var=['in_out','latitude','longitude','ride_6_7', 'ride_7_8', 'ride_8_9', \n",
    "           'ride_9_10','ride_10_11', 'ride_11_12','ride_6_12',\n",
    "           'takeoff_6_7', 'takeoff_7_8', 'takeoff_8_9','takeoff_9_10', \n",
    "           'takeoff_10_11', 'takeoff_11_12','takeoff_6_12',\n",
    "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4',\n",
    "           'weekday_5', 'weekday_6', \n",
    "           'dis_jejusi', 'dis_seoquipo']\n",
    "target=['ride_18_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "holi = ['2019-09-12','2019-09-13','2019-09-14', '2019-10-03','2019-10-09']\n",
    "wkend = ['2019-09-01','2019-09-07','2019-09-08','2019-09-14','2019-09-15',\n",
    "         '2019-09-21','2019-09-22','2019-09-28','2019-09-29',\n",
    "        '2019-10-05','2019-10-06','2019-10-12','2019-10-13']\n",
    "workday = sorted(list(set(pd.concat([train.date,test.date],axis=0).astype('str').unique()) - set(holi+wkend)))\n",
    "train['day_type'] =  np.where(train.date.isin(holi),1, \n",
    "                            np.where(train.date.isin(wkend),2,3))\n",
    "test['day_type'] =  np.where(test.date.isin(holi),1, \n",
    "                            np.where(test.date.isin(wkend),2,3))\n",
    "\n",
    "\n",
    "\n",
    "train = pd.get_dummies(train,columns=['day_type'])\n",
    "test = pd.get_dummies(test,columns=['day_type'])\n",
    "\n",
    "added += [a for a in train.columns if 'day_type' in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([train,test],axis=0).reset_index()\n",
    "\n",
    "for aaa in ['bus_route_id','station_code','station_name']:\n",
    "    temp = all.groupby(aaa)['id'].count().reset_index().\\\n",
    "    rename(columns = {'id' : str(aaa) + '_freq'})\n",
    "\n",
    "    train = pd.merge(train,temp,how='left',on=aaa)\n",
    "    test = pd.merge(test,temp,how='left',on=aaa)\n",
    "    \n",
    "    \n",
    "    \n",
    "del all\n",
    "added += [a for a in train.columns if 'freq' in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\yeonjun.in\\\\Desktop\\\\연준\\\\캐글\\\\제주도\\\\data')\n",
    "move_18_20 = pd.read_pickle('move_18_20.pkl')\n",
    "all = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "\n",
    "remove_outlier =\\\n",
    "move_18_20[~((move_18_20.x < 126.46) | ((move_18_20['x'] > 126.56) & (move_18_20['y'] > 33.5)))].reset_index(drop=True)\n",
    "\n",
    "logic1 = ((all.latitude < 33.5) & (all.latitude > 33.47)) & ((all.longitude > 126.47) & (all.longitude < 126.50))\n",
    "logic2 = ((all.latitude < 33.53) & (all.latitude > 33.48)) & ((all.longitude > 126.51) & (all.longitude < 126.54))\n",
    "logic3 = ((all.latitude < 33.26) & (all.latitude > 33.24)) & ((all.longitude > 126.55) & (all.longitude < 126.57))\n",
    "\n",
    "all['high_move'] = np.where(logic1,'1',np.where(logic2,'2',np.where(logic3,'3','0')))\n",
    "all = pd.get_dummies(all,columns=['high_move'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\yeonjun.in\\\\Desktop\\\\연준\\\\캐글\\\\제주도\\\\data')\n",
    "move_18_20 = pd.read_pickle('move_18_20.pkl')\n",
    "all = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "\n",
    "remove_outlier =\\\n",
    "move_18_20[~((move_18_20.x < 126.46) | ((move_18_20['x'] > 126.56) & (move_18_20['y'] > 33.5)))].reset_index(drop=True)\n",
    "\n",
    "logic1 = ((all.latitude < 33.5) & (all.latitude > 33.47)) & ((all.longitude > 126.47) & (all.longitude < 126.50))\n",
    "logic2 = ((all.latitude < 33.53) & (all.latitude > 33.48)) & ((all.longitude > 126.51) & (all.longitude < 126.54))\n",
    "logic3 = ((all.latitude < 33.26) & (all.latitude > 33.24)) & ((all.longitude > 126.55) & (all.longitude < 126.57))\n",
    "\n",
    "all['high_move'] = np.where(logic1,'1',np.where(logic2,'2',np.where(logic3,'3','0')))\n",
    "all = pd.get_dummies(all,columns=['high_move'])\n",
    "\n",
    "train = all.loc[:(train.shape[0]-1),]\n",
    "test = all.loc[train.shape[0]:,].drop('ride_18_20',axis=1).reset_index(drop=True)\n",
    "\n",
    "del all\n",
    "\n",
    "added += [a for a in train.columns if 'high_move' in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "\n",
    "logic1 = ((remove_outlier.y < 33.5) & (remove_outlier.y > 33.47)) & ((remove_outlier.x > 126.47) & (remove_outlier.x < 126.50))\n",
    "logic2 = ((remove_outlier.y < 33.53) & (remove_outlier.y > 33.48)) & ((remove_outlier.x > 126.51) & (remove_outlier.x < 126.54))\n",
    "logic3 = ((remove_outlier.y < 33.26) & (remove_outlier.y > 33.24)) & ((remove_outlier.x > 126.55) & (remove_outlier.x < 126.57))\n",
    "\n",
    "which1 = (remove_outlier[logic1].y.mean(), remove_outlier[logic1].x.mean())\n",
    "which2 = (remove_outlier[logic2].y.mean(), remove_outlier[logic2].x.mean())\n",
    "which3 = (remove_outlier[logic3].y.mean(), remove_outlier[logic3].x.mean())\n",
    "\n",
    "import geopy.distance\n",
    "all['dis_1'] = [geopy.distance.vincenty((all['latitude'].iloc[i],all['longitude'].iloc[i]), which1).km for i in range(len(all))]\n",
    "all['dis_2'] = [geopy.distance.vincenty((all['latitude'].iloc[i],all['longitude'].iloc[i]), which2).km for i in range(len(all))] \n",
    "all['dis_3']  = [geopy.distance.vincenty((all['latitude'].iloc[i],all['longitude'].iloc[i]), which3).km for i in range(len(all))]\n",
    "\n",
    "train = all.loc[:(train.shape[0]-1),]\n",
    "test = all.loc[train.shape[0]:,].drop('ride_18_20',axis=1).reset_index(drop=True)\n",
    "\n",
    "del all\n",
    "\n",
    "added += ['dis_1','dis_2','dis_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\yeonjun.in\\\\Desktop\\\\연준\\\\캐글\\\\제주도\\\\data')\n",
    "sep = pd.read_pickle('sep_move.pkl')\n",
    "octo = pd.read_pickle('octo_move.pkl')\n",
    "\n",
    "total = pd.concat([sep,octo],axis=0)\n",
    "total[['x','y']] = round(total[['x','y']],2)\n",
    "temp = total.groupby(['x','y'])['move_18_20'].sum().reset_index().\\\n",
    "rename(columns = {'x' : 'longitude','y':'latitude'})\n",
    "\n",
    "all = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "all[['latitude','longitude']] = round(all[['latitude','longitude']],2)\n",
    "\n",
    "all = pd.merge(all,temp,how='left',on=['latitude','longitude'])\n",
    "all['move_18_20'] = all['move_18_20'].fillna(0).astype('int')\n",
    "\n",
    "train = all.loc[:(train.shape[0]-1),]\n",
    "test = all.loc[train.shape[0]:,].drop('ride_18_20',axis=1).reset_index(drop=True)\n",
    "\n",
    "del all\n",
    "\n",
    "added += ['move_18_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "\n",
    "for col in ['station_code','station_name','bus_route_id']:\n",
    "    temp = all.groupby([col])['ride_6_12'].agg(['mean','max','min','count']).reset_index().\\\n",
    "        rename(columns = {'mean' : col+'_'+'ride_6_12'+'_'+'mean_morning',\n",
    "                         'max' : col+'_'+'ride_6_12'+'_'+'max_morning',\n",
    "                         'min' : col+'_'+'ride_6_12'+'_'+'min_morning',\n",
    "                         'count' : col+'_'+'ride_6_12'+'_'+'count_morning'})\n",
    "    all = pd.merge(all,temp,how='left',on=col)\n",
    "\n",
    "train = all.loc[:(train.shape[0]-1),]\n",
    "test = all.loc[train.shape[0]:,].drop('ride_18_20',axis=1).reset_index(drop=True)\n",
    "\n",
    "del all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "\n",
    "for col in ['station_code','station_name','bus_route_id']:\n",
    "    temp = all.groupby([col])['takeoff_6_12'].agg(['mean','max','min','count']).reset_index().\\\n",
    "        rename(columns = {'mean' : col+'_'+'takeoff_6_12'+'_'+'mean_morning',\n",
    "                         'max' : col+'_'+'takeoff_6_12'+'_'+'max_morning',\n",
    "                         'min' : col+'_'+'takeoff_6_12'+'_'+'min_morning',\n",
    "                         'count' : col+'_'+'takeoff_6_12'+'_'+'count_morning'})\n",
    "    all = pd.merge(all,temp,how='left',on=col)\n",
    "\n",
    "train = all.loc[:(train.shape[0]-1),]\n",
    "test = all.loc[train.shape[0]:,].drop('ride_18_20',axis=1).reset_index(drop=True)\n",
    "\n",
    "del all\n",
    "\n",
    "added += [a for a in train.columns if '_morning' in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var = input_var + added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\yeonjun.in\\\\Desktop\\\\연준\\\\캐글\\\\제주도\\\\data')\n",
    "train.to_pickle('fixed2_train.pkl')\n",
    "test.to_pickle('fixed2_test.pkl')\n",
    "pd.DataFrame(columns = input_var).to_csv('fixed2_input_var.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
